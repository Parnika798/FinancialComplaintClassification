{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# This adds your project's 'src' folder to the Python path\n",
    "# It goes up one level ('..') from 'notebooks' and then into 'src'\n",
    "module_path = os.path.abspath(os.path.join('..', 'src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:47:33.401573Z",
     "iopub.status.busy": "2025-09-25T12:47:33.401334Z",
     "iopub.status.idle": "2025-09-25T12:47:37.593705Z",
     "shell.execute_reply": "2025-09-25T12:47:37.592932Z",
     "shell.execute_reply.started": "2025-09-25T12:47:33.401545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use Kaggle's pre-installed packages - no custom installation needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:47:58.213555Z",
     "iopub.status.busy": "2025-09-25T12:47:58.213072Z",
     "iopub.status.idle": "2025-09-25T12:47:58.511838Z",
     "shell.execute_reply": "2025-09-25T12:47:58.511309Z",
     "shell.execute_reply.started": "2025-09-25T12:47:58.213531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Standard ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:48:06.701982Z",
     "iopub.status.busy": "2025-09-25T12:48:06.701455Z",
     "iopub.status.idle": "2025-09-25T12:48:42.934296Z",
     "shell.execute_reply": "2025-09-25T12:48:42.933653Z",
     "shell.execute_reply.started": "2025-09-25T12:48:06.701961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "Using device: cuda\n",
      "GPU: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-25 12:48:24.931143: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758804505.250653      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1758804505.339990      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers library loaded successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check what's available in Kaggle environment\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not available - using CPU fallback\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "try:\n",
    "    from transformers import (\n",
    "        DistilBertTokenizer, \n",
    "        DistilBertForSequenceClassification,\n",
    "        TrainingArguments, \n",
    "        Trainer,\n",
    "    )\n",
    "    print(\"Transformers library loaded successfully\")\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Transformers not available - will use alternative approach\")\n",
    "    TRANSFORMERS_AVAILABLE = False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:48:48.180680Z",
     "iopub.status.busy": "2025-09-25T12:48:48.179722Z",
     "iopub.status.idle": "2025-09-25T12:49:12.240735Z",
     "shell.execute_reply": "2025-09-25T12:49:12.240037Z",
     "shell.execute_reply.started": "2025-09-25T12:48:48.180655Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1113992, 2)\n",
      "                                               label  \\\n",
      "0                        Checking or savings account   \n",
      "1                                    Debt collection   \n",
      "2  Credit reporting, credit repair services, or o...   \n",
      "3  Credit reporting, credit repair services, or o...   \n",
      "4                                           Mortgage   \n",
      "\n",
      "                                      complaint_text  \n",
      "0  Hi, I have been banking with Wells Fargo for o...  \n",
      "1  XXXX is attempting to collect funds for Valuat...  \n",
      "2  Today I called to get my balance and reset my ...  \n",
      "3  The Federal Trade Commission Bureau of Consume...  \n",
      "4  We applied for a home loan using agent XXXX XX...  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: LOAD DATASET (KAGGLE FRIENDLY)\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import the specific variable you want from your config\n",
    "from config import CLEANED_DATA_FILE\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data using the imported path\n",
    "df_cleaned = pd.read_excel(CLEANED_DATA_FILE)\n",
    "\n",
    "# Display the first few rows to check\n",
    "df_cleaned.head()\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:49:27.960975Z",
     "iopub.status.busy": "2025-09-25T12:49:27.960445Z",
     "iopub.status.idle": "2025-09-25T12:49:40.237906Z",
     "shell.execute_reply": "2025-09-25T12:49:40.237322Z",
     "shell.execute_reply.started": "2025-09-25T12:49:27.960956Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: (1113992, 2)\n",
      "Columns: ['label', 'complaint_text']\n",
      "After removing nulls: (1113992, 2)\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "Credit reporting, credit repair services, or other personal consumer reports    515503\n",
      "Debt collection                                                                 192045\n",
      "Mortgage                                                                         97783\n",
      "Credit card or prepaid card                                                      81866\n",
      "Checking or savings account                                                      54264\n",
      "Student loan                                                                     32713\n",
      "Credit reporting                                                                 31588\n",
      "Money transfer, virtual currency, or money service                               26578\n",
      "Vehicle loan or lease                                                            19886\n",
      "Credit card                                                                      18838\n",
      "Name: count, dtype: int64\n",
      "Removing 1 small classes\n",
      "Final dataset: (1113976, 2)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: LOAD AND PREPARE DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Basic data cleaning\n",
    "if 'complaint_text' not in df.columns or 'label' not in df.columns:\n",
    "    print(\"Column names found:\")\n",
    "    for i, col in enumerate(df.columns):\n",
    "        print(f\"  {i}: {col}\")\n",
    "    \n",
    "    # Try to auto-detect text and label columns\n",
    "    text_col = None\n",
    "    label_col = None\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if 'text' in col.lower() or 'complaint' in col.lower() or 'narrative' in col.lower():\n",
    "            text_col = col\n",
    "        elif 'label' in col.lower() or 'category' in col.lower() or 'class' in col.lower():\n",
    "            label_col = col\n",
    "    \n",
    "    if text_col and label_col:\n",
    "        df = df.rename(columns={text_col: 'complaint_text', label_col: 'label'})\n",
    "        print(f\"Auto-detected: text='{text_col}', label='{label_col}'\")\n",
    "    else:\n",
    "        raise ValueError(\"Could not find complaint_text and label columns\")\n",
    "\n",
    "# Remove missing values\n",
    "df = df.dropna(subset=['complaint_text', 'label']).reset_index(drop=True)\n",
    "print(f\"After removing nulls: {df.shape}\")\n",
    "\n",
    "# Show label distribution\n",
    "print(\"\\nLabel distribution:\")\n",
    "label_counts = df['label'].value_counts()\n",
    "print(label_counts.head(10))\n",
    "\n",
    "# Remove very small classes\n",
    "min_samples = 100\n",
    "small_classes = label_counts[label_counts < min_samples].index.tolist()\n",
    "if small_classes:\n",
    "    print(f\"Removing {len(small_classes)} small classes\")\n",
    "    df = df[~df['label'].isin(small_classes)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Final dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:50:01.629226Z",
     "iopub.status.busy": "2025-09-25T12:50:01.628980Z",
     "iopub.status.idle": "2025-09-25T12:50:02.161839Z",
     "shell.execute_reply": "2025-09-25T12:50:02.161263Z",
     "shell.execute_reply.started": "2025-09-25T12:50:01.629210Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 classes: ['Credit reporting, credit repair services, or other personal consumer reports', 'Debt collection', 'Mortgage', 'Credit card or prepaid card', 'Checking or savings account']\n",
      "  Credit reporting, credit repair services, or other personal consumer reports: 515503 -> 5000\n",
      "  Debt collection: 192045 -> 5000\n",
      "  Mortgage: 97783 -> 5000\n",
      "  Credit card or prepaid card: 81866 -> 5000\n",
      "  Checking or savings account: 54264 -> 5000\n",
      "Sampled dataset created: 25000 rows\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: SAMPLE TOP 5 CLASSES, 10k SAMPLES EACH\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sample_top_n_classes(df, top_n=5, samples_per_class=10000, random_state=42):\n",
    "    \"\"\"\n",
    "    Take top N classes and sample a fixed number of rows per class.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    samples = []\n",
    "\n",
    "    # Get top N classes by count\n",
    "    top_classes = df['label'].value_counts().head(top_n).index.tolist()\n",
    "    print(f\"Top {top_n} classes: {top_classes}\")\n",
    "\n",
    "    for label in top_classes:\n",
    "        label_df = df[df['label'] == label]\n",
    "        count = len(label_df)\n",
    "        # Sample with replacement if not enough rows\n",
    "        if count >= samples_per_class:\n",
    "            sampled = label_df.sample(n=samples_per_class, random_state=random_state)\n",
    "        else:\n",
    "            sampled = label_df.sample(n=samples_per_class, replace=True, random_state=random_state)\n",
    "\n",
    "        samples.append(sampled)\n",
    "        print(f\"  {label}: {count} -> {samples_per_class}\")\n",
    "\n",
    "    # Combine and shuffle\n",
    "    sample_df = pd.concat(samples).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    print(f\"Sampled dataset created: {len(sample_df)} rows\")\n",
    "    return sample_df\n",
    "\n",
    "# Create the sampled dataset\n",
    "sample_df = sample_top_n_classes(df, top_n=5, samples_per_class=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:50:10.312781Z",
     "iopub.status.busy": "2025-09-25T12:50:10.312514Z",
     "iopub.status.idle": "2025-09-25T12:50:10.376535Z",
     "shell.execute_reply": "2025-09-25T12:50:10.375787Z",
     "shell.execute_reply.started": "2025-09-25T12:50:10.312760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:50:13.540985Z",
     "iopub.status.busy": "2025-09-25T12:50:13.540200Z",
     "iopub.status.idle": "2025-09-25T12:50:18.180012Z",
     "shell.execute_reply": "2025-09-25T12:50:18.179237Z",
     "shell.execute_reply.started": "2025-09-25T12:50:13.540960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading translation model: Helsinki-NLP/opus-mt-en-hi\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58023c50774e44529dc1bcc0038e8305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b21f2c2d2f44b1bc3832c0d137578a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0560f155c44cfca9ee718c431807d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8d799fd2414f6591cdd6bad0cb0fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e36083b2d404cdd9b17e46e3905f3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de81240e97114f0d957b59010f1adf39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e516a24abc4b569d69cd2ad708297a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84ab5d852464e77b263b73e87b73f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(61950, 512, padding_idx=61949)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(61950, 512, padding_idx=61949)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(61950, 512, padding_idx=61949)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=61950, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================  \n",
    "# STEP 4: LOAD HELSINKI NLP TRANSLATION MODEL (EN -> HI)  \n",
    "# ============================================================================  \n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "print(f\"Loading translation model: {model_name}\")\n",
    "\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:50:26.685044Z",
     "iopub.status.busy": "2025-09-25T12:50:26.684771Z",
     "iopub.status.idle": "2025-09-25T12:50:26.695462Z",
     "shell.execute_reply": "2025-09-25T12:50:26.694749Z",
     "shell.execute_reply.started": "2025-09-25T12:50:26.685024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================  \n",
    "# STEP 5: TRANSLATION FUNCTIONS  \n",
    "# ============================================================================  \n",
    "\n",
    "def translate_text_to_hindi(text, max_length=512):\n",
    "    \"\"\"Translate single English text to Hindi\"\"\"\n",
    "    try:\n",
    "        text = str(text).strip()\n",
    "        if len(text) == 0:\n",
    "            return \"शिकायत\"\n",
    "        if len(text) > 400:\n",
    "            text = text[:400] + \"...\"\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "        hindi_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return hindi_text.strip() if hindi_text else f\"शिकायत: {text[:50]}...\"\n",
    "    except:\n",
    "        return f\"शिकायत: {text[:50]}...\"\n",
    "\n",
    "def translate_batch_to_hindi(texts, batch_size=16):\n",
    "    \"\"\"Translate batch of texts\"\"\"\n",
    "    all_translations = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        try:\n",
    "            clean_batch = [str(t).strip()[:400] + \"...\" if len(str(t)) > 400 else str(t).strip() for t in batch]\n",
    "            inputs = tokenizer(clean_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n",
    "            batch_translations = [tokenizer.decode(o, skip_special_tokens=True).strip() for o in outputs]\n",
    "            all_translations.extend(batch_translations)\n",
    "        except:\n",
    "            for t in batch:\n",
    "                all_translations.append(translate_text_to_hindi(t))\n",
    "    return all_translations\n",
    "\n",
    "def translate_sample_dataset(sample_df, batch_size=16):\n",
    "    \"\"\"Translate only the sample dataset\"\"\"\n",
    "    print(f\"Translating sample dataset ({len(sample_df):,} rows)...\")\n",
    "    complaint_texts = sample_df['complaint_text'].tolist()\n",
    "    hindi_translations = translate_batch_to_hindi(complaint_texts, batch_size=batch_size)\n",
    "    sample_df_with_hindi = sample_df.copy()\n",
    "    sample_df_with_hindi['complaint_text_hindi'] = hindi_translations\n",
    "    print(\"Translation completed!\")\n",
    "    return sample_df_with_hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:50:32.198152Z",
     "iopub.status.busy": "2025-09-25T12:50:32.197887Z",
     "iopub.status.idle": "2025-09-25T12:50:32.202798Z",
     "shell.execute_reply": "2025-09-25T12:50:32.202036Z",
     "shell.execute_reply.started": "2025-09-25T12:50:32.198131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:50:35.441910Z",
     "iopub.status.busy": "2025-09-25T12:50:35.441641Z",
     "iopub.status.idle": "2025-09-25T12:50:38.837094Z",
     "shell.execute_reply": "2025-09-25T12:50:38.836294Z",
     "shell.execute_reply.started": "2025-09-25T12:50:35.441891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357d50b0abaf4771a61d7ec7c5fa49d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per text: 0.34 sec\n",
      "Estimated total translation time: 141.13 min (2.35 hr)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Take a small sample (e.g., 100 texts)\n",
    "sample_texts = sample_df['complaint_text'].tolist()[:10]\n",
    "\n",
    "start_time = time.time()\n",
    "_ = translate_batch_to_hindi(sample_texts, batch_size=16)\n",
    "end_time = time.time()\n",
    "\n",
    "time_per_text = (end_time - start_time) / len(sample_texts)\n",
    "total_texts = len(sample_df)\n",
    "\n",
    "estimated_total_time_sec = time_per_text * total_texts\n",
    "estimated_total_time_min = estimated_total_time_sec / 60\n",
    "estimated_total_time_hr = estimated_total_time_min / 60\n",
    "\n",
    "print(f\"Time per text: {time_per_text:.2f} sec\")\n",
    "print(f\"Estimated total translation time: {estimated_total_time_min:.2f} min ({estimated_total_time_hr:.2f} hr)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T12:50:54.757560Z",
     "iopub.status.busy": "2025-09-25T12:50:54.756807Z",
     "iopub.status.idle": "2025-09-25T14:41:44.816350Z",
     "shell.execute_reply": "2025-09-25T14:41:44.815677Z",
     "shell.execute_reply.started": "2025-09-25T12:50:54.757528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating sample dataset (25,000 rows)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2234e007cb3547f19176238eaf16da88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Translating:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation completed!\n",
      "Saved translated sample dataset to 'sample_top5_translated.csv'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================  \n",
    "# STEP 6: TRANSLATE AND SAVE  \n",
    "# ============================================================================  \n",
    "\n",
    "sample_df_with_hindi = translate_sample_dataset(sample_df, batch_size=16)\n",
    "sample_df_with_hindi.to_csv(\"sample_top5_translated.csv\", index=False)\n",
    "print(\"Saved translated sample dataset to 'sample_top5_translated.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-25T15:21:25.963914Z",
     "iopub.status.busy": "2025-09-25T15:21:25.963611Z",
     "iopub.status.idle": "2025-09-25T15:21:25.969295Z",
     "shell.execute_reply": "2025-09-25T15:21:25.968568Z",
     "shell.execute_reply.started": "2025-09-25T15:21:25.963892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='sample_top5_translated.csv' target='_blank'>sample_top5_translated.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/sample_top5_translated.csv"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(\"sample_top5_translated.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Emergency stop & save your data\n",
    "import os, signal\n",
    "import pandas as pd\n",
    "\n",
    "# Attempt to stop all child Python processes\n",
    "os.kill(os.getpid(), signal.SIGINT)\n",
    "\n",
    "# Immediately save your current data (20k samples) safely\n",
    "try:\n",
    "    sample_df_with_hindi.to_csv(\"sample_top5_translated.csv\", index=False)\n",
    "    print(\"Saved 20k samples to 'sample_top5_translated.csv'\")\n",
    "except:\n",
    "    print(\"Could not save - maybe kernel is too busy. Try saving after stopping the loop manually.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8305771,
     "sourceId": 13111699,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
